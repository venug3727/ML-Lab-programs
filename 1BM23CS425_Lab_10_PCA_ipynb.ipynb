{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nmf7yvNzAqwg",
        "outputId": "7563239f-490f-44c0-b1f9-930813085e40"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Performance Without PCA:\n",
            "Logistic Regression Accuracy: 0.8533\n",
            "Random Forest Accuracy: 0.8804\n",
            "SVM Accuracy: 0.8641\n",
            "\n",
            "Model Performance With PCA:\n",
            "Logistic Regression Accuracy: 0.8533\n",
            "Random Forest Accuracy: 0.8533\n",
            "SVM Accuracy: 0.8587\n",
            "\n",
            "Comparison of Results:\n",
            "Model                Original Acc    PCA Acc        \n",
            "Logistic Regression  0.8533          0.8533         \n",
            "Random Forest        0.8804          0.8533         \n",
            "SVM                  0.8641          0.8587         \n",
            "\n",
            "PCA Explained Variance Ratio:\n",
            "Component 1: 0.2614\n",
            "Component 2: 0.1528\n",
            "Component 3: 0.1110\n",
            "Component 4: 0.0948\n",
            "Component 5: 0.0787\n",
            "Component 6: 0.0708\n",
            "Component 7: 0.0421\n",
            "Component 8: 0.0372\n",
            "Component 9: 0.0364\n",
            "Component 10: 0.0323\n",
            "Component 11: 0.0276\n",
            "Component 12: 0.0214\n",
            "Component 13: 0.0187\n",
            "Component 14: 0.0088\n",
            "Component 15: 0.0061\n",
            "Component 16: 0.0000\n",
            "Component 17: 0.0000\n",
            "Component 18: 0.0000\n",
            "Component 19: 0.0000\n",
            "Component 20: 0.0000\n",
            "\n",
            "Total Variance Explained by all components: 1.0000\n",
            "\n",
            "Cumulative Explained Variance:\n",
            "Components 1: 0.2614\n",
            "Components 2: 0.4143\n",
            "Components 3: 0.5252\n",
            "Components 4: 0.6200\n",
            "Components 5: 0.6987\n",
            "Components 6: 0.7695\n",
            "Components 7: 0.8116\n",
            "Components 8: 0.8488\n",
            "Components 9: 0.8852\n",
            "Components 10: 0.9174\n",
            "Components 11: 0.9450\n",
            "Components 12: 0.9664\n",
            "Components 13: 0.9851\n",
            "Components 14: 0.9939\n",
            "Components 15: 1.0000\n",
            "Components 16: 1.0000\n",
            "Components 17: 1.0000\n",
            "Components 18: 1.0000\n",
            "Components 19: 1.0000\n",
            "Components 20: 1.0000\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/heart.csv')\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop('HeartDisease', axis=1)\n",
        "y = df['HeartDisease']\n",
        "\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = ['Sex', 'ChestPainType', 'RestingECG', 'ExerciseAngina', 'ST_Slope']\n",
        "numerical_cols = ['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_cols),\n",
        "        ('cat', OneHotEncoder(), categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Models to evaluate\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
        "    \"SVM\": SVC(random_state=42)\n",
        "}\n",
        "\n",
        "# Function to evaluate models\n",
        "def evaluate_models(X_train, X_test, y_train, y_test, preprocessor, models):\n",
        "    results = {}\n",
        "    for name, model in models.items():\n",
        "        # Create pipeline\n",
        "        pipeline = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('classifier', model)\n",
        "        ])\n",
        "\n",
        "        # Train model\n",
        "        pipeline.fit(X_train, y_train)\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = pipeline.predict(X_test)\n",
        "\n",
        "        # Calculate accuracy\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        results[name] = accuracy\n",
        "\n",
        "        print(f\"{name} Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "    return results\n",
        "\n",
        "# Evaluate models without PCA\n",
        "print(\"Model Performance Without PCA:\")\n",
        "original_results = evaluate_models(X_train, X_test, y_train, y_test, preprocessor, models)\n",
        "\n",
        "# Now with PCA\n",
        "print(\"\\nModel Performance With PCA:\")\n",
        "\n",
        "# Update preprocessor to include PCA\n",
        "pca_preprocessor = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('pca', PCA(n_components=0.95))  # Keep 95% of variance\n",
        "])\n",
        "\n",
        "pca_results = evaluate_models(X_train, X_test, y_train, y_test, pca_preprocessor, models)\n",
        "\n",
        "# Compare results\n",
        "print(\"\\nComparison of Results:\")\n",
        "print(\"{:<20} {:<15} {:<15}\".format('Model', 'Original Acc', 'PCA Acc'))\n",
        "for model in models.keys():\n",
        "    print(\"{:<20} {:<15.4f} {:<15.4f}\".format(\n",
        "        model,\n",
        "        original_results[model],\n",
        "        pca_results[model]\n",
        "    ))\n",
        "\n",
        "# Optional: Analyze PCA components\n",
        "full_pipeline = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('pca', PCA())\n",
        "])\n",
        "\n",
        "full_pipeline.fit(X_train)\n",
        "pca = full_pipeline.named_steps['pca']\n",
        "\n",
        "# Print explained variance\n",
        "print(\"\\nPCA Explained Variance Ratio:\")\n",
        "for i, ratio in enumerate(pca.explained_variance_ratio_):\n",
        "    print(f\"Component {i+1}: {ratio:.4f}\")\n",
        "\n",
        "print(f\"\\nTotal Variance Explained by all components: {sum(pca.explained_variance_ratio_):.4f}\")\n",
        "\n",
        "# Determine optimal number of components\n",
        "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
        "print(\"\\nCumulative Explained Variance:\")\n",
        "for i, variance in enumerate(cumulative_variance):\n",
        "    print(f\"Components {i+1}: {variance:.4f}\")"
      ]
    }
  ]
}